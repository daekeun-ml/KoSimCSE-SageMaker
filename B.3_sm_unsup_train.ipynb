{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca5acad3-5ccd-4bf0-a1c7-2fb592fa09ec",
   "metadata": {},
   "source": [
    "# KoSimCSE training (Unsupervised) on SageMaker\n",
    "---\n",
    "\n",
    "## Overview \n",
    "바로 이전 모듈까지는 기존에 온프레미스에서 개발했던 환경과 동일한 환경으로 모델을 빌드하고 훈련했습니다. 하지만 아래와 같은 상황들에서도 기존 환경을 사용하는 것이 바람직할까요?\n",
    "\n",
    "- 온프레미스의 GPU가 총 1장으로 훈련 시간이 너무 오래 소요됨\n",
    "- 가용 서버 대수가 2대인데 10개의 딥러닝 모델을 동시에 훈련해야 함\n",
    "- 필요한 상황에만 GPU를 활용\n",
    "\n",
    "Amazon SageMaker는 데이터 과학자들 및 머신 러닝 엔지니어들을 위한 완전 관리형 머신 러닝 서비스로 훈련 및 추론 수행 시 인프라 설정에 대한 추가 작업이 필요하지 있기에, 단일 GPU 기반의 딥러닝 훈련을 포함한 멀티 GPU 및 멀티 인스턴스 분산 훈련을 보다 쉽고 빠르게 수행할 수 있습니다. SageMaker는 다양한 유즈케이스들에 적합한 예제들을 지속적으로 업데이트하고 있으며, 한국어 세션 및 자료들도 제공되고 있습니다.\n",
    "\n",
    "### Note\n",
    "- 이미 기본적인 Hugging Face 용법 및 자연어 처리에 익숙하신 분들은 앞 모듈을 생략하고 이 모듈부터 핸즈온을 시작하셔도 됩니다.\n",
    "- 이 노트북은 SageMaker 기본 API를 참조하므로, SageMaker Studio, SageMaker 노트북 인스턴스 또는 AWS CLI가 설정된 로컬 시스템에서 실행해야 합니다. SageMaker Studio 또는 SageMaker 노트북 인스턴스를 사용하는 경우 PyTorch 기반 커널을 선택하세요.\n",
    "- 훈련(Training) job 수행 시 최소 `ml.g4dn.xlarge` 훈련 인스턴스를 권장하며, 분산 훈련 수행 시에는 `ml.g5.12xlarge` 훈련 인스턴스를 권장합니다. 만약 인스턴스 사용에 제한이 걸려 있다면 [Request a service quota increase for SageMaker resources](https://docs.aws.amazon.com/sagemaker/latest/dg/regions-quotas.html#service-limit-increase-request-procedure)를 참조하여 인스턴스 제한을 해제해 주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f5230d-ebb1-4640-a695-d98bf066e2e4",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. Preparation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52bd530d-d95e-48d6-9f46-94d2eb0c903c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker role arn: arn:aws:iam::143656149352:role/service-role/AmazonSageMaker-ExecutionRole-20220317T150353\n",
      "SageMaker bucket: sagemaker-us-east-1-143656149352\n",
      "SageMaker session region: us-east-1\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "region = boto3.Session().region_name\n",
    "bucket = None\n",
    "if bucket is None and sess is not None:\n",
    "    bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=bucket)\n",
    "\n",
    "print(f\"SageMaker role arn: {role}\")\n",
    "print(f\"SageMaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"SageMaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81b057cb-9163-4f24-97e4-a3c38421b8d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%bash\n",
    "# aws configure set default.s3.max_concurrent_requests 100\n",
    "# aws configure set default.s3.max_queue_size 10000\n",
    "# aws configure set default.s3.multipart_threshold 1GB\n",
    "# aws configure set default.s3.multipart_chunksize 64MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d544a14e-1d50-404c-b1f8-4c5286ac2a60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket_prefix = \"korsimcse\"\n",
    "model_name = \"roberta-base\"\n",
    "\n",
    "#dataset_dir = \"dataset-unsup-train\"\n",
    "s3_model_path = f\"s3://{bucket}/{bucket_prefix}/model/{model_name}/\"\n",
    "s3_dataset_path = f\"s3://{bucket}/{bucket_prefix}/dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e591409-f3e1-4547-a24c-cc3d21258902",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !aws s3 sync {dataset_dir} {s3_dataset_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b4d3d1-0507-4d9e-8cae-ce3670e6975e",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 2. SageMaker Training\n",
    "---\n",
    "\n",
    "SageMaker에 대한 대표적인 오해가 여전히 많은 분들이 SageMaker 훈련을 위해 소스 코드를 전면적으로 수정해야 한다고 생각합니다. 하지만, 실제로는 별도의 소스 코드 수정 없이 기존 여러분이 사용했던 파이썬 스크립트에 SageMaker 훈련에 필요한 SageMaker 전용 환경 변수들만 추가하면 됩니다.\n",
    "\n",
    "SageMaker 훈련은 훈련 작업을 호출할 때, 1) 훈련 EC2 인스턴스 프로비저닝 - 2) 컨테이너 구동을 위한 도커 이미지 및 훈련 데이터 다운로드 - 3) 컨테이너 구동 - 4) 컨테이너 환경에서 훈련 수행 - 5) 컨테이너 환경에서 S3의 특정 버킷에 저장 - 6) 훈련 인스턴스 종료로 구성됩니다. 따라서, 훈련 수행 로직은 아래 예시와 같이 기존 개발 환경과 동일합니다.\n",
    "\n",
    "`/opt/conda/bin/python train_hf.py --num_epochs 5 --train_batch_size 32 ...`\n",
    "\n",
    "이 과정에서 컨테이너 환경에 필요한 환경 변수(예: 모델 경로, 훈련 데이터 경로) 들은 사전에 지정되어 있으며, 이 환경 변수들이 설정되어 있어야 훈련에 필요한 파일들의 경로를 인식할 수 있습니다. 대표적인 환경 변수들에 대한 자세한 내용은 https://github.com/aws/sagemaker-containers#important-environment-variables 을 참조하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ef16b9-6466-47d4-9b63-6be95dcf4222",
   "metadata": {},
   "source": [
    "### Setup SageMaker Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60062873-c1a8-4fcf-a38d-c8860e852b23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "entry_point = \"unsup_run.sh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b61dee20-0628-46d3-b70d-cc915cc6fe1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.interactive_apps.base_interactive_app:NOTEBOOK_METADATA_FILE detected but failed to get valid domain and user from it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kosimcse-roberta-base-unsupervised-2023-10-05-08-45\n"
     ]
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# Define Training Job Name \n",
    "job_name = f\"kosimcse-{model_name}-unsupervised-{time.strftime('%Y-%m-%d-%H-%M', time.localtime())}\"\n",
    "print(job_name)\n",
    "\n",
    "# See https://github.com/aws/deep-learning-containers/blob/master/available_images.md\n",
    "image_uri = f\"763104351884.dkr.ecr.{region}.amazonaws.com/pytorch-training:2.0.1-gpu-py310-cu118-ubuntu20.04-sagemaker\"\n",
    "hparams = {}\n",
    "\n",
    "instance_type = \"ml.g5.12xlarge\"\n",
    "max_run = 6*60*60 # 6 hours\n",
    "use_spot_instances = False\n",
    "if use_spot_instances:\n",
    "    max_wait = 12*60*60 # 12 hours: spot instance waiting + max runtime\n",
    "else:\n",
    "    max_wait = None\n",
    "    \n",
    "# Create the Estimator\n",
    "estimator = PyTorch(\n",
    "    image_uri=image_uri,\n",
    "    entry_point=entry_point,           # train script\n",
    "    source_dir=\"src\",               # directory which includes all the files needed for training\n",
    "    instance_type=instance_type, # instances type used for the training job\n",
    "    instance_count=1,               # the number of instances used for training\n",
    "    base_job_name=job_name,         # the name of the training job\n",
    "    role=role,                      # Iam role used in training job to access AWS ressources, e.g. S3\n",
    "    volume_size=300,                # the size of the EBS volume in GB\n",
    "    py_version=\"py310\",             # the python version used in the training job\n",
    "    hyperparameters=hparams,\n",
    "    debugger_hook_config=False,\n",
    "    disable_profile=True,\n",
    "    use_spot_instances=use_spot_instances,\n",
    "    max_run=max_run,\n",
    "    max_wait=max_wait if use_spot_instances else None,\n",
    "    metric_definitions=[\n",
    "       {'Name': 'train:step', 'Regex': 'step:(.*?);'},\n",
    "       {'Name': 'train:loss', 'Regex': 'loss:(.*?);'},\n",
    "       {'Name': 'train:avg-sts-score', 'Regex': 'Avg. STS:(.*?);'}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d799465-6567-45fe-8f05-195499b15861",
   "metadata": {},
   "source": [
    "### Start Training job\n",
    "S3에서 훈련 인스턴스로 복사될 데이터를 지정한 후 SageMaker 훈련 job을 시작합니다. 모델 크기, 데이터 세트 크기에 따라서 몇십 분에서 몇 시간까지 소요될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bea0a770-ab7d-4813-80ca-266ef96a1a40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: kosimcse-roberta-base-unsupervised-2023-2023-10-05-08-45-35-241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    }
   ],
   "source": [
    "fast_file = lambda x: TrainingInput(x, input_mode=\"FastFile\")\n",
    "estimator.fit(\n",
    "    {\n",
    "        \"training\": fast_file(s3_dataset_path),\n",
    "    },\n",
    "    wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c354ab-bed7-4d3e-b120-779bbf044040",
   "metadata": {},
   "source": [
    "### View Training Job\n",
    "SageMaker 콘솔 창에서 훈련 내역을 직접 확인할 수도 있지만, 아래 코드 셀에서 생성되는 링크를 클릭하면 더 편리하게 훈련 내역을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cbbe7d5a-3839-475a-bfe5-5356684477a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b> [Fine-tuning] Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/jobs/kosimcse-roberta-base-unsupervised-2023-2023-10-05-08-45-35-241\">Training Job</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b> [Fine-tuning] Review <a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region=us-east-1#logStream:group=/aws/sagemaker/TrainingJobs;prefix=kosimcse-roberta-base-unsupervised-2023-2023-10-05-08-45-35-241;streamFilter=typeLogStreamPrefix\">CloudWatch Logs</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "def make_console_link(region, train_job_name, train_task='[Training]'):\n",
    "    train_job_link = f'<b> {train_task} Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={region}#/jobs/{train_job_name}\">Training Job</a></b>'   \n",
    "    cloudwatch_link = f'<b> {train_task} Review <a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region={region}#logStream:group=/aws/sagemaker/TrainingJobs;prefix={train_job_name};streamFilter=typeLogStreamPrefix\">CloudWatch Logs</a></b>'\n",
    "    return train_job_link, cloudwatch_link  \n",
    "        \n",
    "train_job_name = estimator.latest_training_job.job_name\n",
    "train_job_link, cloudwatch_link = make_console_link(region, train_job_name, '[Fine-tuning]')\n",
    "\n",
    "display(HTML(train_job_link))\n",
    "display(HTML(cloudwatch_link))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae7ea38-72c6-4be9-97de-3e896d3eedbd",
   "metadata": {},
   "source": [
    "### Wait for the training jobs to complete\n",
    "훈련이 완료될 때까지 기다립니다. estimator.fit(...)에서 wait=False로 설정한 경우, 아래 코드 셀의 주석을 해제 후 실행하여 동기 방식으로 변경할 수도 있습니다. 훈련 완료까지는 수십 분이 소요됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "062d1b9c-6b73-45e6-8dca-82a130ec773c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-05 10:10:36 Starting - Preparing the instances for training\n",
      "2023-10-05 10:10:36 Downloading - Downloading input data\n",
      "2023-10-05 10:10:36 Training - Training image download completed. Training in progress.\n",
      "2023-10-05 10:10:36 Uploading - Uploading generated training model\n",
      "2023-10-05 10:10:36 Completed - Training job completed\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-10-05 08:51:42,592 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-10-05 08:51:42,623 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-10-05 08:51:42,632 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-10-05 08:51:42,634 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-10-05 08:51:44,879 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-10-05 08:51:44,920 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-10-05 08:51:44,960 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-10-05 08:51:44,969 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.12xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.12xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"kosimcse-roberta-base-unsupervised-2023-2023-10-05-08-45-35-241\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-143656149352/kosimcse-roberta-base-unsupervised-2023-2023-10-05-08-45-35-241/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"unsup_run.sh\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 48,\n",
      "    \"num_gpus\": 4,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.12xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.12xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"unsup_run.sh\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=unsup_run.sh\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.12xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.12xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=unsup_run.sh\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=48\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-143656149352/kosimcse-roberta-base-unsupervised-2023-2023-10-05-08-45-35-241/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.12xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"kosimcse-roberta-base-unsupervised-2023-2023-10-05-08-45-35-241\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-143656149352/kosimcse-roberta-base-unsupervised-2023-2023-10-05-08-45-35-241/source/sourcedir.tar.gz\",\"module_name\":\"unsup_run.sh\",\"network_interface_name\":\"eth0\",\"num_cpus\":48,\"num_gpus\":4,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.12xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.12xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"unsup_run.sh\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/bin/sh -c \"./unsup_run.sh \"\u001b[0m\n",
      "\u001b[34m2023-10-05 08:51:44,990 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mCollecting transformers (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for transformers from https://files.pythonhosted.org/packages/1a/d1/3bba59606141ae808017f6fde91453882f931957f125009417b87a281067/transformers-4.34.0-py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.34.0-py3-none-any.whl.metadata (121 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.5/121.5 kB 9.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting datasets (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for datasets from https://files.pythonhosted.org/packages/09/7e/fd4d6441a541dba61d0acb3c1fd5df53214c2e9033854e837a99dd9e0793/datasets-2.14.5-py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.14.5-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mCollecting more-itertools (from -r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for more-itertools from https://files.pythonhosted.org/packages/5a/cb/6dce742ea14e47d6f565589e859ad225f2a5de576d7696e0623b784e226b/more_itertools-10.1.0-py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading more_itertools-10.1.0-py3-none-any.whl.metadata (33 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (3.12.4)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub<1.0,>=0.16.4 (from transformers->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/aa/f3/3fc97336a0e90516901befd4f500f08d691034d387406fdbde85bea827cc/huggingface_hub-0.17.3-py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (1.24.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (6.0.1)\u001b[0m\n",
      "\u001b[34mCollecting regex!=2019.12.17 (from transformers->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for regex!=2019.12.17 from https://files.pythonhosted.org/packages/8f/3e/4b8b40eb3c80aeaf360f0361d956d129bb3d23b2a3ecbe3a04a8f3bdd6d3/regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.9/40.9 kB 11.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (2.31.0)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers<0.15,>=0.14 (from transformers->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for tokenizers<0.15,>=0.14 from https://files.pythonhosted.org/packages/57/bd/45b5ef6b088880779f70acf60027f7043ca5fa1b98f4a4345cf3aea09044/tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting safetensors>=0.3.1 (from transformers->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for safetensors>=0.3.1 from https://files.pythonhosted.org/packages/6c/f0/c17bbdb1e5f9dab29d44cade445135789f75f8f08ea2728d04493ea8412b/safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers->-r requirements.txt (line 1)) (4.65.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (13.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (0.3.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (2.1.1)\u001b[0m\n",
      "\u001b[34mCollecting xxhash (from datasets->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for xxhash from https://files.pythonhosted.org/packages/80/8a/1dd41557883b6196f8f092011a5c1f72d4d44cf36d7b67d4a5efe3127949/xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->-r requirements.txt (line 2)) (0.70.15)\u001b[0m\n",
      "\u001b[34mCollecting fsspec[http]<2023.9.0,>=2023.1.0 (from datasets->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for fsspec[http]<2023.9.0,>=2023.1.0 from https://files.pythonhosted.org/packages/e3/bd/4c0a4619494188a9db5d77e2100ab7d544a42e76b2447869d8e124e981d8/fsspec-2023.6.0-py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading fsspec-2023.6.0-py3-none-any.whl.metadata (6.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiohttp (from datasets->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for aiohttp from https://files.pythonhosted.org/packages/3e/f6/fcda07dd1e72260989f0b22dde999ecfe80daa744f23ca167083683399bc/aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (23.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r requirements.txt (line 2)) (3.1.0)\u001b[0m\n",
      "\u001b[34mCollecting multidict<7.0,>=4.5 (from aiohttp->datasets->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 114.5/114.5 kB 29.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->datasets->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for async-timeout<5.0,>=4.0.0a3 from https://files.pythonhosted.org/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting yarl<2.0,>=1.0 (from aiohttp->datasets->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 268.8/268.8 kB 49.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting frozenlist>=1.1.1 (from aiohttp->datasets->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/1e/28/74b8b6451c89c070d34e753d8b65a1e4ce508a6808b18529f36e8c0e2184/frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiosignal>=1.1.2 (from aiohttp->datasets->-r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers->-r requirements.txt (line 1)) (4.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 1)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 1)) (1.26.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->-r requirements.txt (line 1)) (2023.7.22)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub<1.0,>=0.16.4 (from transformers->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/7f/c4/adcbe9a696c135578cabcbdd7331332daad4d49b7c43688bc2d36b3a47d2/huggingface_hub-0.16.4-py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.16.4-py3-none-any.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 2)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 2)) (2023.3.post1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r requirements.txt (line 2)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->-r requirements.txt (line 2)) (1.16.0)\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.7/7.7 MB 101.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.14.5-py3-none-any.whl (519 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 519.6/519.6 kB 66.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading more_itertools-10.1.0-py3-none-any.whl (55 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.8/55.8 kB 16.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading aiohttp-3.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 87.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 773.9/773.9 kB 81.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 92.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.8/3.8 MB 106.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 268.8/268.8 kB 48.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 194.1/194.1 kB 46.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\u001b[0m\n",
      "\u001b[34mDownloading frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (225 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 225.7/225.7 kB 51.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading fsspec-2023.6.0-py3-none-any.whl (163 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 163.8/163.8 kB 35.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mInstalling collected packages: safetensors, xxhash, regex, multidict, more-itertools, fsspec, frozenlist, async-timeout, yarl, huggingface-hub, aiosignal, tokenizers, aiohttp, transformers, datasets\u001b[0m\n",
      "\u001b[34mAttempting uninstall: fsspec\u001b[0m\n",
      "\u001b[34mFound existing installation: fsspec 2023.9.2\u001b[0m\n",
      "\u001b[34mUninstalling fsspec-2023.9.2:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled fsspec-2023.9.2\u001b[0m\n",
      "\u001b[34mSuccessfully installed aiohttp-3.8.5 aiosignal-1.3.1 async-timeout-4.0.3 datasets-2.14.5 frozenlist-1.4.0 fsspec-2023.6.0 huggingface-hub-0.16.4 more-itertools-10.1.0 multidict-6.0.4 regex-2023.10.3 safetensors-0.3.3 tokenizers-0.14.0 transformers-4.34.0 xxhash-3.4.1 yarl-1.9.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mtorchrun --nnodes 1 --nproc_per_node 4 unsup_train_ddp.py --base_model klue/roberta-base --output_dir /opt/ml/model/ --batch_size 64 --num_epochs 1 --learning_rate 1e-5 --temperature 0.05 --lr_scheduler_type linear --max_seq_len 32 --eval_steps 50 --seed 42 --lora_dropout 0.05\u001b[0m\n",
      "\u001b[34mWARNING:torch.distributed.run:\u001b[0m\n",
      "\u001b[34m*****************************************\u001b[0m\n",
      "\u001b[34mSetting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \u001b[0m\n",
      "\u001b[34m*****************************************\u001b[0m\n",
      "\u001b[34m10/05/2023 08:52:03 - INFO - root -   Initialized the distributed environment. world_size=4, rank=0, local_rank=0\u001b[0m\n",
      "\u001b[34mDownloading readme:   0%|          | 0.00/387 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading readme: 100%|██████████| 387/387 [00:00<00:00, 397kB/s]\u001b[0m\n",
      "\u001b[34mDownloading data files:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/302M [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:   4%|▍         | 12.6M/302M [00:00<00:03, 96.4MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  12%|█▏        | 37.7M/302M [00:00<00:01, 147MB/s] #033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  21%|██        | 62.9M/302M [00:00<00:01, 166MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  29%|██▉       | 88.1M/302M [00:00<00:01, 168MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  37%|███▋      | 113M/302M [00:00<00:01, 182MB/s] #033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  46%|████▌     | 138M/302M [00:00<00:00, 190MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  54%|█████▍    | 164M/302M [00:00<00:00, 197MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  62%|██████▏   | 189M/302M [00:01<00:00, 199MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  71%|███████   | 214M/302M [00:01<00:00, 204MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  79%|███████▉  | 239M/302M [00:01<00:00, 207MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  87%|████████▋ | 264M/302M [00:01<00:00, 209MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  96%|█████████▌| 289M/302M [00:01<00:00, 209MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 302M/302M [00:01<00:00, 194MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data files: 100%|██████████| 1/1 [00:01<00:00,  1.56s/it]\u001b[0m\n",
      "\u001b[34mDownloading data files: 100%|██████████| 1/1 [00:01<00:00,  1.56s/it]\u001b[0m\n",
      "\u001b[34mExtracting data files:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mExtracting data files: 100%|██████████| 1/1 [00:00<00:00, 2121.55it/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 0 examples [00:00, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 100000 examples [00:00, 846100.03 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 220000 examples [00:00, 977369.01 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 340000 examples [00:00, 1020908.30 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 460000 examples [00:00, 1042637.78 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 580000 examples [00:00, 1050351.13 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 700000 examples [00:00, 1059306.05 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 820000 examples [00:00, 1052846.21 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 940000 examples [00:00, 1062947.67 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 1060000 examples [00:01, 1059105.83 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 1180000 examples [00:01, 1060124.96 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 1300000 examples [00:01, 1064305.05 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 1410000 examples [00:01, 1051505.78 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 1530000 examples [00:01, 1051816.09 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 1650000 examples [00:01, 1062334.12 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 1770000 examples [00:01, 1067410.15 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 1890000 examples [00:01, 1063501.47 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 2010000 examples [00:01, 1068898.92 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 2130000 examples [00:02, 1072211.72 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 2250000 examples [00:02, 1077409.44 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 2370000 examples [00:02, 1082881.21 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 2490000 examples [00:02, 1099406.76 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 2610000 examples [00:02, 1101698.85 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 2730000 examples [00:02, 1094070.86 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 2850000 examples [00:02, 1098871.17 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 2970000 examples [00:02, 1084597.15 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 3090000 examples [00:02, 1086945.75 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 3210000 examples [00:03, 1097355.05 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 3330000 examples [00:03, 1094854.96 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 3450000 examples [00:03, 1080320.49 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 3570000 examples [00:03, 1092949.48 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 3690000 examples [00:03, 1116808.99 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 3810000 examples [00:03, 1124933.91 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 3930000 examples [00:03, 1102380.67 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 4050000 examples [00:03, 1082770.01 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 4170000 examples [00:03, 1076553.36 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 4290000 examples [00:03, 1073222.15 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 4410000 examples [00:04, 1066887.35 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 4530000 examples [00:04, 1064174.08 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 4650000 examples [00:04, 1051309.60 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 4724064 examples [00:04, 1069089.44 examples/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)okenizer_config.json:   0%|          | 0.00/375 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)okenizer_config.json: 100%|██████████| 375/375 [00:00<00:00, 3.07MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)solve/main/vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)solve/main/vocab.txt: 100%|██████████| 248k/248k [00:00<00:00, 38.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)/main/tokenizer.json:   0%|          | 0.00/752k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)/main/tokenizer.json: 100%|██████████| 752k/752k [00:00<00:00, 59.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)cial_tokens_map.json:   0%|          | 0.00/173 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)cial_tokens_map.json: 100%|██████████| 173/173 [00:00<00:00, 2.39MB/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)lve/main/config.json:   0%|          | 0.00/546 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading (…)lve/main/config.json: 100%|██████████| 546/546 [00:00<00:00, 5.41MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:   0%|          | 0.00/443M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  12%|█▏        | 52.4M/443M [00:00<00:00, 464MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  24%|██▎       | 105M/443M [00:00<00:00, 483MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  36%|███▌      | 157M/443M [00:00<00:00, 408MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  47%|████▋     | 210M/443M [00:00<00:00, 430MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  59%|█████▉    | 262M/443M [00:00<00:00, 454MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  71%|███████   | 315M/443M [00:00<00:00, 469MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  83%|████████▎ | 367M/443M [00:00<00:00, 447MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors:  95%|█████████▍| 419M/443M [00:00<00:00, 430MB/s]\u001b[0m\n",
      "\u001b[34mDownloading model.safetensors: 100%|██████████| 443M/443M [00:01<00:00, 442MB/s]\u001b[0m\n",
      "\u001b[34mNCCL version 2.17.1+cuda11.8\u001b[0m\n",
      "\u001b[34malgo-1:69:223 [0] nccl_net_ofi_init:1472 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34malgo-1:71:224 [2] nccl_net_ofi_init:1472 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34malgo-1:72:226 [3] nccl_net_ofi_init:1472 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34malgo-1:70:225 [1] nccl_net_ofi_init:1472 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34mDownloading builder script:   0%|          | 0.00/23.3k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading builder script: 100%|██████████| 23.3k/23.3k [00:00<00:00, 34.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading metadata:   0%|          | 0.00/22.7k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading metadata: 100%|██████████| 22.7k/22.7k [00:00<00:00, 27.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading readme:   0%|          | 0.00/21.5k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading readme: 100%|██████████| 21.5k/21.5k [00:00<00:00, 30.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/1.35M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading data:   1%|          | 14.3k/1.35M [00:00<00:17, 76.1kB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:   3%|▎         | 45.1k/1.35M [00:00<00:10, 127kB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:   8%|▊         | 105k/1.35M [00:00<00:05, 215kB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:  17%|█▋        | 225k/1.35M [00:00<00:02, 380kB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:  35%|███▍      | 466k/1.35M [00:00<00:01, 703kB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:  70%|███████   | 947k/1.35M [00:01<00:00, 1.33MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 1.35M/1.35M [00:01<00:00, 1.19MB/s]\u001b[0m\n",
      "\u001b[34mGenerating train split:   0%|          | 0/11668 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split:   0%|          | 1/11668 [00:00<40:14,  4.83 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split:  14%|█▎        | 1579/11668 [00:00<00:01, 6445.85 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split:  27%|██▋       | 3165/11668 [00:00<00:00, 9912.30 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split:  42%|████▏     | 4870/11668 [00:00<00:00, 12259.45 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split:  55%|█████▌    | 6450/11668 [00:00<00:00, 13418.64 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split:  69%|██████▉   | 8035/11668 [00:00<00:00, 14189.53 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split:  83%|████████▎ | 9695/11668 [00:00<00:00, 14943.07 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split:  97%|█████████▋| 11279/11668 [00:00<00:00, 15217.55 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 100%|██████████| 11668/11668 [00:00<00:00, 12346.64 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating validation split:   0%|          | 0/519 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerating validation split: 100%|██████████| 519/519 [00:00<00:00, 13766.25 examples/s]\u001b[0m\n",
      "\u001b[34mDownloading readme:   0%|          | 0.00/1.63k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading readme: 100%|██████████| 1.63k/1.63k [00:00<00:00, 1.45MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data files:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/542k [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 542k/542k [00:00<00:00, 15.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/130k [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 130k/130k [00:00<00:00, 5.09MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/165k [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 165k/165k [00:00<00:00, 5.57MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data files: 100%|██████████| 3/3 [00:00<00:00, 31.83it/s]\u001b[0m\n",
      "\u001b[34mExtracting data files:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mExtracting data files: 100%|██████████| 3/3 [00:00<00:00, 2638.48it/s]\u001b[0m\n",
      "\u001b[34mGenerating train split:   0%|          | 0/5691 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 100%|██████████| 5691/5691 [00:00<00:00, 1044903.87 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating test split:   0%|          | 0/1376 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerating test split: 100%|██████████| 1376/1376 [00:00<00:00, 666747.03 examples/s]\u001b[0m\n",
      "\u001b[34mGenerating valid split:   0%|          | 0/1465 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerating valid split: 100%|██████████| 1465/1465 [00:00<00:00, 687091.06 examples/s]\u001b[0m\n",
      "\u001b[34mepoch:   0;#011step:      0;#011loss:          nan;#011Avg. STS: 21.02486;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   0%|#033[34m          #033[0m| 0/18453 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   0%|#033[34m          #033[0m| 50/18453 [00:19<1:59:28,  2.57it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:     50;#011loss: 0.0010530399;#011Avg. STS: 75.67482;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   1%|#033[34m          #033[0m| 100/18453 [00:32<1:37:32,  3.14it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:    100;#011loss: 0.0004521132;#011Avg. STS: 76.33138;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   1%|#033[34m          #033[0m| 150/18453 [00:47<1:33:32,  3.26it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:    150;#011loss: 0.0004527397;#011Avg. STS: 77.24636;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   1%|#033[34m          #033[0m| 200/18453 [01:02<1:31:27,  3.33it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:    200;#011loss: 0.0002707097;#011Avg. STS: 77.62641;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   1%|#033[34m▏         #033[0m| 250/18453 [01:16<1:30:16,  3.36it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:    250;#011loss: 0.0003512228;#011Avg. STS: 77.65549;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   2%|#033[34m▏         #033[0m| 300/18453 [01:31<1:29:45,  3.37it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:    300;#011loss: 0.0008376634;#011Avg. STS: 77.81115;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   2%|#033[34m▏         #033[0m| 350/18453 [01:46<1:29:03,  3.39it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:    350;#011loss: 0.0001663950;#011Avg. STS: 78.18314;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   2%|#033[34m▏         #033[0m| 400/18453 [02:00<1:27:56,  3.42it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:    400;#011loss: 0.0001844114;#011Avg. STS: 78.23692;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   2%|#033[34m▏         #033[0m| 450/18453 [02:14<1:26:56,  3.45it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:    450;#011loss: 0.0001208823;#011Avg. STS: 78.25207;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   3%|#033[34m▎         #033[0m| 500/18453 [02:28<1:26:15,  3.47it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:    500;#011loss: 0.0001298961;#011Avg. STS: 78.35089;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   3%|#033[34m▎         #033[0m| 550/18453 [02:43<1:25:40,  3.48it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:    550;#011loss: 0.0001141567;#011Avg. STS: 78.39418;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   3%|#033[34m▎         #033[0m| 600/18453 [02:57<1:25:13,  3.49it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:    600;#011loss: 0.0000967523;#011Avg. STS: 78.48537;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   4%|#033[34m▎         #033[0m| 650/18453 [03:11<1:24:47,  3.50it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:    650;#011loss: 0.0001586025;#011Avg. STS: 78.60056;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   4%|#033[34m▍         #033[0m| 700/18453 [03:25<1:24:34,  3.50it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:    700;#011loss: 0.0001458971;#011Avg. STS: 78.72136;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   4%|#033[34m▍         #033[0m| 750/18453 [03:40<1:24:16,  3.50it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:    750;#011loss: 0.0001201010;#011Avg. STS: 78.81780;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   4%|#033[34m▍         #033[0m| 800/18453 [03:54<1:23:59,  3.50it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:    800;#011loss: 0.0001273628;#011Avg. STS: 78.88381;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   5%|#033[34m▍         #033[0m| 850/18453 [04:08<1:23:44,  3.50it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:    850;#011loss: 0.0000708957;#011Avg. STS: 78.88349;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   5%|#033[34m▍         #033[0m| 900/18453 [04:20<1:19:52,  3.66it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:    900;#011loss: 0.0000902379;#011Avg. STS: 78.89682;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   5%|#033[34m▌         #033[0m| 950/18453 [04:35<1:20:43,  3.61it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:    950;#011loss: 0.0001487838;#011Avg. STS: 78.78657;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   5%|#033[34m▌         #033[0m| 1000/18453 [04:47<1:17:41,  3.74it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   1000;#011loss: 0.0002759567;#011Avg. STS: 78.85413;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   6%|#033[34m▌         #033[0m| 1050/18453 [04:59<1:15:28,  3.84it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   1050;#011loss: 0.0000765502;#011Avg. STS: 79.06636;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   6%|#033[34m▌         #033[0m| 1100/18453 [05:13<1:17:28,  3.73it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   1100;#011loss: 0.0000804965;#011Avg. STS: 79.31896;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   6%|#033[34m▌         #033[0m| 1150/18453 [05:28<1:18:45,  3.66it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   1150;#011loss: 0.0001299598;#011Avg. STS: 79.76151;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   7%|#033[34m▋         #033[0m| 1200/18453 [05:42<1:19:35,  3.61it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   1200;#011loss: 0.0000758717;#011Avg. STS: 79.33467;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   7%|#033[34m▋         #033[0m| 1250/18453 [05:54<1:16:40,  3.74it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   1250;#011loss: 0.0001193844;#011Avg. STS: 79.61649;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   7%|#033[34m▋         #033[0m| 1300/18453 [06:06<1:14:33,  3.83it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   1300;#011loss: 0.0000905094;#011Avg. STS: 79.70677;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   7%|#033[34m▋         #033[0m| 1350/18453 [06:19<1:12:59,  3.91it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   1350;#011loss: 0.0000726561;#011Avg. STS: 79.69267;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   8%|#033[34m▊         #033[0m| 1400/18453 [06:31<1:12:21,  3.93it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   1400;#011loss: 0.0000461711;#011Avg. STS: 79.73085;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   8%|#033[34m▊         #033[0m| 1450/18453 [06:43<1:11:17,  3.97it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   1450;#011loss: 0.0001643100;#011Avg. STS: 79.59324;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   8%|#033[34m▊         #033[0m| 1500/18453 [06:56<1:10:26,  4.01it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   1500;#011loss: 0.0007589423;#011Avg. STS: 80.05214;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   8%|#033[34m▊         #033[0m| 1550/18453 [07:10<1:13:14,  3.85it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   1550;#011loss: 0.0000634724;#011Avg. STS: 80.00967;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   9%|#033[34m▊         #033[0m| 1600/18453 [07:22<1:11:41,  3.92it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   1600;#011loss: 0.0000516407;#011Avg. STS: 79.93291;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   9%|#033[34m▉         #033[0m| 1650/18453 [07:34<1:10:34,  3.97it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   1650;#011loss: 0.0000727224;#011Avg. STS: 79.92668;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   9%|#033[34m▉         #033[0m| 1700/18453 [07:47<1:09:42,  4.01it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   1700;#011loss: 0.0000854147;#011Avg. STS: 80.08733;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:   9%|#033[34m▉         #033[0m| 1750/18453 [08:01<1:12:30,  3.84it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   1750;#011loss: 0.0000530232;#011Avg. STS: 80.12275;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  10%|#033[34m▉         #033[0m| 1800/18453 [08:15<1:14:15,  3.74it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   1800;#011loss: 0.0000423420;#011Avg. STS: 80.15318;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  10%|#033[34m█         #033[0m| 1850/18453 [08:29<1:15:24,  3.67it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   1850;#011loss: 0.0000453013;#011Avg. STS: 80.11406;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  10%|#033[34m█         #033[0m| 1900/18453 [08:41<1:12:47,  3.79it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   1900;#011loss: 0.0000405426;#011Avg. STS: 80.11533;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  11%|#033[34m█         #033[0m| 1950/18453 [08:54<1:10:55,  3.88it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   1950;#011loss: 0.0000379837;#011Avg. STS: 80.08625;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  11%|#033[34m█         #033[0m| 2000/18453 [09:06<1:09:32,  3.94it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   2000;#011loss: 0.0000506870;#011Avg. STS: 80.10139;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  11%|#033[34m█         #033[0m| 2050/18453 [09:18<1:08:31,  3.99it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   2050;#011loss: 0.0000400378;#011Avg. STS: 80.10501;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  11%|#033[34m█▏        #033[0m| 2100/18453 [09:30<1:07:45,  4.02it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   2100;#011loss: 0.0000350857;#011Avg. STS: 80.09532;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  12%|#033[34m█▏        #033[0m| 2150/18453 [09:42<1:07:15,  4.04it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   2150;#011loss: 0.0000324112;#011Avg. STS: 80.15594;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  12%|#033[34m█▏        #033[0m| 2200/18453 [09:57<1:10:03,  3.87it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   2200;#011loss: 0.0000493284;#011Avg. STS: 80.04544;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  12%|#033[34m█▏        #033[0m| 2250/18453 [10:09<1:08:36,  3.94it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   2250;#011loss: 0.0000462657;#011Avg. STS: 80.12557;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  12%|#033[34m█▏        #033[0m| 2300/18453 [10:21<1:07:36,  3.98it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   2300;#011loss: 0.0000501438;#011Avg. STS: 80.11277;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  13%|#033[34m█▎        #033[0m| 2350/18453 [10:33<1:06:47,  4.02it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   2350;#011loss: 0.0000445777;#011Avg. STS: 80.11127;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  13%|#033[34m█▎        #033[0m| 2400/18453 [10:45<1:06:09,  4.04it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   2400;#011loss: 0.0001159270;#011Avg. STS: 80.06473;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  13%|#033[34m█▎        #033[0m| 2450/18453 [10:58<1:05:37,  4.06it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   2450;#011loss: 0.0000500846;#011Avg. STS: 80.19028;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  14%|#033[34m█▎        #033[0m| 2500/18453 [11:12<1:08:27,  3.88it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   2500;#011loss: 0.0000483050;#011Avg. STS: 80.26489;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  14%|#033[34m█▍        #033[0m| 2550/18453 [11:26<1:10:33,  3.76it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   2550;#011loss: 0.0000355177;#011Avg. STS: 80.38660;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  14%|#033[34m█▍        #033[0m| 2600/18453 [11:40<1:11:46,  3.68it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   2600;#011loss: 0.0000367858;#011Avg. STS: 80.34698;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  14%|#033[34m█▍        #033[0m| 2650/18453 [11:52<1:09:21,  3.80it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   2650;#011loss: 0.0000371230;#011Avg. STS: 80.34603;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  15%|#033[34m█▍        #033[0m| 2700/18453 [12:05<1:07:37,  3.88it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   2700;#011loss: 0.0000312115;#011Avg. STS: 80.37044;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  15%|#033[34m█▍        #033[0m| 2750/18453 [12:17<1:06:20,  3.95it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   2750;#011loss: 0.0000691808;#011Avg. STS: 80.40405;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  15%|#033[34m█▌        #033[0m| 2800/18453 [12:31<1:08:34,  3.80it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   2800;#011loss: 0.0000296042;#011Avg. STS: 80.38055;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  15%|#033[34m█▌        #033[0m| 2850/18453 [12:43<1:06:51,  3.89it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   2850;#011loss: 0.0000670738;#011Avg. STS: 80.40859;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  16%|#033[34m█▌        #033[0m| 2900/18453 [12:57<1:08:44,  3.77it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   2900;#011loss: 0.0000339605;#011Avg. STS: 80.52417;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  16%|#033[34m█▌        #033[0m| 2950/18453 [13:12<1:10:01,  3.69it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   2950;#011loss: 0.0000334092;#011Avg. STS: 80.46540;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  16%|#033[34m█▋        #033[0m| 3000/18453 [13:24<1:07:43,  3.80it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   3000;#011loss: 0.0000498586;#011Avg. STS: 80.41353;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  17%|#033[34m█▋        #033[0m| 3050/18453 [13:36<1:06:00,  3.89it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   3050;#011loss: 0.0000370486;#011Avg. STS: 80.19147;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  17%|#033[34m█▋        #033[0m| 3100/18453 [13:48<1:04:46,  3.95it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   3100;#011loss: 0.0000464865;#011Avg. STS: 80.51327;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  17%|#033[34m█▋        #033[0m| 3150/18453 [14:01<1:03:57,  3.99it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   3150;#011loss: 0.0000254395;#011Avg. STS: 80.57386;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  17%|#033[34m█▋        #033[0m| 3200/18453 [14:15<1:06:26,  3.83it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   3200;#011loss: 0.0000364654;#011Avg. STS: 80.57204;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  18%|#033[34m█▊        #033[0m| 3250/18453 [14:27<1:04:56,  3.90it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   3250;#011loss: 0.0000499156;#011Avg. STS: 80.56197;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  18%|#033[34m█▊        #033[0m| 3300/18453 [14:39<1:03:48,  3.96it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   3300;#011loss: 0.0000528187;#011Avg. STS: 80.60850;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  18%|#033[34m█▊        #033[0m| 3350/18453 [14:54<1:06:02,  3.81it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   3350;#011loss: 0.0000319191;#011Avg. STS: 80.66962;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  18%|#033[34m█▊        #033[0m| 3400/18453 [15:08<1:07:26,  3.72it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   3400;#011loss: 0.0000288927;#011Avg. STS: 80.75246;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  19%|#033[34m█▊        #033[0m| 3450/18453 [15:22<1:08:24,  3.66it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   3450;#011loss: 0.0000239159;#011Avg. STS: 80.73523;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  19%|#033[34m█▉        #033[0m| 3500/18453 [15:34<1:06:00,  3.78it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   3500;#011loss: 0.0000275870;#011Avg. STS: 80.72359;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  19%|#033[34m█▉        #033[0m| 3550/18453 [15:46<1:04:12,  3.87it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   3550;#011loss: 0.0000242251;#011Avg. STS: 80.67943;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  20%|#033[34m█▉        #033[0m| 3600/18453 [15:59<1:02:50,  3.94it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   3600;#011loss: 0.0000286893;#011Avg. STS: 80.70349;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  20%|#033[34m█▉        #033[0m| 3650/18453 [16:11<1:01:50,  3.99it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   3650;#011loss: 0.0000505411;#011Avg. STS: 80.71646;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  20%|#033[34m██        #033[0m| 3700/18453 [16:23<1:01:04,  4.03it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   3700;#011loss: 0.0000307453;#011Avg. STS: 80.72040;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  20%|#033[34m██        #033[0m| 3750/18453 [16:35<1:00:28,  4.05it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   3750;#011loss: 0.0000319152;#011Avg. STS: 80.82108;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  21%|#033[34m██        #033[0m| 3800/18453 [16:49<1:03:00,  3.88it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   3800;#011loss: 0.0000287881;#011Avg. STS: 80.73961;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  21%|#033[34m██        #033[0m| 3850/18453 [17:01<1:01:52,  3.93it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   3850;#011loss: 0.0000237146;#011Avg. STS: 80.71732;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  21%|#033[34m██        #033[0m| 3900/18453 [17:14<1:00:50,  3.99it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   3900;#011loss: 0.0000560741;#011Avg. STS: 80.85776;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  21%|#033[34m██▏       #033[0m| 3950/18453 [17:28<1:03:01,  3.84it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   3950;#011loss: 0.0000306491;#011Avg. STS: 80.82824;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  22%|#033[34m██▏       #033[0m| 4000/18453 [17:40<1:01:33,  3.91it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   4000;#011loss: 0.0000411702;#011Avg. STS: 80.75305;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  22%|#033[34m██▏       #033[0m| 4050/18453 [17:52<1:00:29,  3.97it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   4050;#011loss: 0.0000289258;#011Avg. STS: 80.75606;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  22%|#033[34m██▏       #033[0m| 4100/18453 [18:04<59:39,  4.01it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   4100;#011loss: 0.0000220720;#011Avg. STS: 80.77290;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  22%|#033[34m██▏       #033[0m| 4150/18453 [18:17<59:00,  4.04it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   4150;#011loss: 0.0000214481;#011Avg. STS: 80.74920;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  23%|#033[34m██▎       #033[0m| 4200/18453 [18:29<58:28,  4.06it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   4200;#011loss: 0.0000186542;#011Avg. STS: 80.75525;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  23%|#033[34m██▎       #033[0m| 4250/18453 [18:41<58:01,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   4250;#011loss: 0.0000236569;#011Avg. STS: 80.81259;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  23%|#033[34m██▎       #033[0m| 4300/18453 [18:53<57:40,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   4300;#011loss: 0.0000229269;#011Avg. STS: 80.80942;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  24%|#033[34m██▎       #033[0m| 4350/18453 [19:05<57:23,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   4350;#011loss: 0.0000224799;#011Avg. STS: 80.85914;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  24%|#033[34m██▍       #033[0m| 4400/18453 [19:19<59:56,  3.91it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   4400;#011loss: 0.0000214462;#011Avg. STS: 80.83819;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  24%|#033[34m██▍       #033[0m| 4450/18453 [19:31<58:52,  3.96it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   4450;#011loss: 0.0000233329;#011Avg. STS: 80.89510;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  24%|#033[34m██▍       #033[0m| 4500/18453 [19:46<1:01:01,  3.81it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   4500;#011loss: 0.0000360692;#011Avg. STS: 81.17424;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  25%|#033[34m██▍       #033[0m| 4550/18453 [20:00<1:02:23,  3.71it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   4550;#011loss: 0.0000277881;#011Avg. STS: 81.02422;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  25%|#033[34m██▍       #033[0m| 4600/18453 [20:12<1:00:24,  3.82it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   4600;#011loss: 0.0000399865;#011Avg. STS: 80.73656;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  25%|#033[34m██▌       #033[0m| 4650/18453 [20:24<58:59,  3.90it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   4650;#011loss: 0.0000380324;#011Avg. STS: 80.81988;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  25%|#033[34m██▌       #033[0m| 4700/18453 [20:37<57:59,  3.95it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   4700;#011loss: 0.0000280711;#011Avg. STS: 80.76022;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  26%|#033[34m██▌       #033[0m| 4750/18453 [20:49<57:10,  3.99it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   4750;#011loss: 0.0000336324;#011Avg. STS: 80.75075;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  26%|#033[34m██▌       #033[0m| 4800/18453 [21:01<56:34,  4.02it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   4800;#011loss: 0.0000238396;#011Avg. STS: 80.84477;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  26%|#033[34m██▋       #033[0m| 4850/18453 [21:13<56:08,  4.04it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   4850;#011loss: 0.0000272368;#011Avg. STS: 81.02982;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  27%|#033[34m██▋       #033[0m| 4900/18453 [21:26<55:40,  4.06it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   4900;#011loss: 0.0000220534;#011Avg. STS: 81.02826;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  27%|#033[34m██▋       #033[0m| 4950/18453 [21:38<55:17,  4.07it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   4950;#011loss: 0.0000215952;#011Avg. STS: 80.98004;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  27%|#033[34m██▋       #033[0m| 5000/18453 [21:50<55:06,  4.07it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   5000;#011loss: 0.0000172740;#011Avg. STS: 80.92107;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  27%|#033[34m██▋       #033[0m| 5050/18453 [22:02<54:55,  4.07it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   5050;#011loss: 0.0000190937;#011Avg. STS: 80.85481;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  28%|#033[34m██▊       #033[0m| 5100/18453 [22:15<54:36,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   5100;#011loss: 0.0000317009;#011Avg. STS: 80.75257;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  28%|#033[34m██▊       #033[0m| 5150/18453 [22:27<54:18,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   5150;#011loss: 0.0000473273;#011Avg. STS: 80.66353;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  28%|#033[34m██▊       #033[0m| 5200/18453 [22:39<54:05,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   5200;#011loss: 0.0000181456;#011Avg. STS: 80.83825;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  28%|#033[34m██▊       #033[0m| 5250/18453 [22:51<53:50,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   5250;#011loss: 0.0000254690;#011Avg. STS: 80.88468;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  29%|#033[34m██▊       #033[0m| 5300/18453 [23:04<53:41,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   5300;#011loss: 0.0000265531;#011Avg. STS: 80.84607;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  29%|#033[34m██▉       #033[0m| 5350/18453 [23:16<53:27,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   5350;#011loss: 0.0000181568;#011Avg. STS: 80.80209;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  29%|#033[34m██▉       #033[0m| 5400/18453 [23:28<53:15,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   5400;#011loss: 0.0000508575;#011Avg. STS: 80.76570;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  30%|#033[34m██▉       #033[0m| 5450/18453 [23:40<53:00,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   5450;#011loss: 0.0000159385;#011Avg. STS: 80.67522;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  30%|#033[34m██▉       #033[0m| 5500/18453 [23:52<52:51,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   5500;#011loss: 0.0000850499;#011Avg. STS: 80.73085;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  30%|#033[34m███       #033[0m| 5550/18453 [24:05<52:37,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   5550;#011loss: 0.0000335452;#011Avg. STS: 80.67376;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  30%|#033[34m███       #033[0m| 5600/18453 [24:17<52:24,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   5600;#011loss: 0.0000349578;#011Avg. STS: 80.81691;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  31%|#033[34m███       #033[0m| 5650/18453 [24:29<52:11,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   5650;#011loss: 0.0000191700;#011Avg. STS: 80.67375;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  31%|#033[34m███       #033[0m| 5700/18453 [24:41<52:03,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   5700;#011loss: 0.0000203211;#011Avg. STS: 80.95107;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  31%|#033[34m███       #033[0m| 5750/18453 [24:54<52:00,  4.07it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   5750;#011loss: 0.0000255155;#011Avg. STS: 81.06154;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  31%|#033[34m███▏      #033[0m| 5800/18453 [25:06<51:48,  4.07it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   5800;#011loss: 0.0000228485;#011Avg. STS: 80.91359;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  32%|#033[34m███▏      #033[0m| 5850/18453 [25:18<51:32,  4.07it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   5850;#011loss: 0.0000219880;#011Avg. STS: 80.95030;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  32%|#033[34m███▏      #033[0m| 5900/18453 [25:31<51:21,  4.07it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   5900;#011loss: 0.0000319724;#011Avg. STS: 80.86654;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  32%|#033[34m███▏      #033[0m| 5950/18453 [25:43<51:10,  4.07it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   5950;#011loss: 0.0000280917;#011Avg. STS: 80.16189;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  33%|#033[34m███▎      #033[0m| 6000/18453 [25:55<50:54,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   6000;#011loss: 0.0001891170;#011Avg. STS: 80.58289;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  33%|#033[34m███▎      #033[0m| 6050/18453 [26:07<50:40,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   6050;#011loss: 0.0000259793;#011Avg. STS: 80.72612;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  33%|#033[34m███▎      #033[0m| 6100/18453 [26:20<50:30,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   6100;#011loss: 0.0000206824;#011Avg. STS: 80.74385;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  33%|#033[34m███▎      #033[0m| 6150/18453 [26:32<50:18,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   6150;#011loss: 0.0000336660;#011Avg. STS: 80.70384;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  34%|#033[34m███▎      #033[0m| 6200/18453 [26:44<50:08,  4.07it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   6200;#011loss: 0.0000202969;#011Avg. STS: 80.66505;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  34%|#033[34m███▍      #033[0m| 6250/18453 [26:56<49:58,  4.07it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   6250;#011loss: 0.0000750244;#011Avg. STS: 80.29815;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  34%|#033[34m███▍      #033[0m| 6300/18453 [27:09<49:45,  4.07it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   6300;#011loss: 0.0000246682;#011Avg. STS: 80.26069;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  34%|#033[34m███▍      #033[0m| 6350/18453 [27:21<49:40,  4.06it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   6350;#011loss: 0.0000234017;#011Avg. STS: 80.53512;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  35%|#033[34m███▍      #033[0m| 6400/18453 [27:33<49:26,  4.06it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   6400;#011loss: 0.0000219936;#011Avg. STS: 79.99309;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  35%|#033[34m███▍      #033[0m| 6450/18453 [27:46<49:12,  4.07it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   6450;#011loss: 0.0000164470;#011Avg. STS: 80.27194;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  35%|#033[34m███▌      #033[0m| 6500/18453 [27:58<48:58,  4.07it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   6500;#011loss: 0.0000210523;#011Avg. STS: 80.32176;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  35%|#033[34m███▌      #033[0m| 6550/18453 [28:10<48:40,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   6550;#011loss: 0.0000236886;#011Avg. STS: 80.14076;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  36%|#033[34m███▌      #033[0m| 6600/18453 [28:22<48:25,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   6600;#011loss: 0.0000239844;#011Avg. STS: 80.17374;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  36%|#033[34m███▌      #033[0m| 6650/18453 [28:35<48:09,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   6650;#011loss: 0.0000200417;#011Avg. STS: 80.25615;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  36%|#033[34m███▋      #033[0m| 6700/18453 [28:47<47:53,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   6700;#011loss: 0.0000534343;#011Avg. STS: 79.67084;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  37%|#033[34m███▋      #033[0m| 6750/18453 [28:59<47:42,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   6750;#011loss: 0.0000229081;#011Avg. STS: 79.62719;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  37%|#033[34m███▋      #033[0m| 6800/18453 [29:11<47:29,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   6800;#011loss: 0.0000300540;#011Avg. STS: 79.81345;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  37%|#033[34m███▋      #033[0m| 6850/18453 [29:24<47:18,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   6850;#011loss: 0.0000302797;#011Avg. STS: 79.97819;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  37%|#033[34m███▋      #033[0m| 6900/18453 [29:36<47:05,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   6900;#011loss: 0.0000211442;#011Avg. STS: 80.03032;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  38%|#033[34m███▊      #033[0m| 6950/18453 [29:48<46:55,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   6950;#011loss: 0.0000320460;#011Avg. STS: 79.65812;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  38%|#033[34m███▊      #033[0m| 7000/18453 [30:00<46:41,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   7000;#011loss: 0.0000181530;#011Avg. STS: 79.78754;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  38%|#033[34m███▊      #033[0m| 7050/18453 [30:12<46:27,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   7050;#011loss: 0.0000191272;#011Avg. STS: 79.92442;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  38%|#033[34m███▊      #033[0m| 7100/18453 [30:25<46:13,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   7100;#011loss: 0.0000439550;#011Avg. STS: 79.73639;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  39%|#033[34m███▊      #033[0m| 7150/18453 [30:37<46:01,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   7150;#011loss: 0.0000238989;#011Avg. STS: 79.88144;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  39%|#033[34m███▉      #033[0m| 7200/18453 [30:49<45:48,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   7200;#011loss: 0.0000287751;#011Avg. STS: 80.12069;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  39%|#033[34m███▉      #033[0m| 7250/18453 [31:01<45:32,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   7250;#011loss: 0.0000217627;#011Avg. STS: 79.84587;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  40%|#033[34m███▉      #033[0m| 7300/18453 [31:13<45:18,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   7300;#011loss: 0.0000145732;#011Avg. STS: 80.11643;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  40%|#033[34m███▉      #033[0m| 7350/18453 [31:26<45:03,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   7350;#011loss: 0.0000130868;#011Avg. STS: 80.19977;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  40%|#033[34m████      #033[0m| 7400/18453 [31:38<44:50,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   7400;#011loss: 0.0000255114;#011Avg. STS: 80.06926;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  40%|#033[34m████      #033[0m| 7450/18453 [31:50<44:40,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   7450;#011loss: 0.0000359824;#011Avg. STS: 80.11473;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  41%|#033[34m████      #033[0m| 7500/18453 [32:02<44:28,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   7500;#011loss: 0.0000179501;#011Avg. STS: 80.01159;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  41%|#033[34m████      #033[0m| 7550/18453 [32:14<44:17,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   7550;#011loss: 0.0000256284;#011Avg. STS: 79.88438;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  41%|#033[34m████      #033[0m| 7600/18453 [32:26<44:05,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   7600;#011loss: 0.0000128465;#011Avg. STS: 79.93185;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  41%|#033[34m████▏     #033[0m| 7650/18453 [32:39<43:53,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   7650;#011loss: 0.0000121834;#011Avg. STS: 79.96363;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  42%|#033[34m████▏     #033[0m| 7700/18453 [32:51<43:47,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   7700;#011loss: 0.0000187212;#011Avg. STS: 79.80492;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  42%|#033[34m████▏     #033[0m| 7750/18453 [33:03<43:35,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   7750;#011loss: 0.0000209823;#011Avg. STS: 80.28362;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  42%|#033[34m████▏     #033[0m| 7800/18453 [33:15<43:18,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   7800;#011loss: 0.0000821949;#011Avg. STS: 80.25980;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  43%|#033[34m████▎     #033[0m| 7850/18453 [33:27<43:02,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   7850;#011loss: 0.0001369233;#011Avg. STS: 79.61293;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  43%|#033[34m████▎     #033[0m| 7900/18453 [33:40<42:50,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   7900;#011loss: 0.0000196562;#011Avg. STS: 79.55949;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  43%|#033[34m████▎     #033[0m| 7950/18453 [33:52<42:38,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   7950;#011loss: 0.0000179016;#011Avg. STS: 79.76124;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  43%|#033[34m████▎     #033[0m| 8000/18453 [34:04<42:28,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   8000;#011loss: 0.0000147836;#011Avg. STS: 79.83670;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  44%|#033[34m████▎     #033[0m| 8050/18453 [34:16<42:22,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   8050;#011loss: 0.0000245465;#011Avg. STS: 79.89051;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  44%|#033[34m████▍     #033[0m| 8100/18453 [34:29<42:15,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   8100;#011loss: 0.0000243978;#011Avg. STS: 79.56178;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  44%|#033[34m████▍     #033[0m| 8150/18453 [34:41<42:02,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   8150;#011loss: 0.0000169964;#011Avg. STS: 79.85042;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  44%|#033[34m████▍     #033[0m| 8200/18453 [34:53<41:55,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   8200;#011loss: 0.0000131744;#011Avg. STS: 79.92466;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  45%|#033[34m████▍     #033[0m| 8250/18453 [35:06<41:53,  4.06it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   8250;#011loss: 0.0000234336;#011Avg. STS: 79.44525;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  45%|#033[34m████▍     #033[0m| 8300/18453 [35:18<41:51,  4.04it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   8300;#011loss: 0.0000162290;#011Avg. STS: 79.75170;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  45%|#033[34m████▌     #033[0m| 8350/18453 [35:30<41:36,  4.05it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   8350;#011loss: 0.0000509291;#011Avg. STS: 78.42348;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  46%|#033[34m████▌     #033[0m| 8400/18453 [35:43<41:17,  4.06it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   8400;#011loss: 0.0000187397;#011Avg. STS: 78.59078;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  46%|#033[34m████▌     #033[0m| 8450/18453 [35:55<41:02,  4.06it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   8450;#011loss: 0.0000197807;#011Avg. STS: 78.78971;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  46%|#033[34m████▌     #033[0m| 8500/18453 [36:07<40:48,  4.07it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   8500;#011loss: 0.0000310218;#011Avg. STS: 78.83489;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  46%|#033[34m████▋     #033[0m| 8550/18453 [36:19<40:32,  4.07it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   8550;#011loss: 0.0000120847;#011Avg. STS: 79.02319;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  47%|#033[34m████▋     #033[0m| 8600/18453 [36:32<40:18,  4.07it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   8600;#011loss: 0.0000136009;#011Avg. STS: 79.22467;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  47%|#033[34m████▋     #033[0m| 8650/18453 [36:44<40:04,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   8650;#011loss: 0.0000115036;#011Avg. STS: 79.37161;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  47%|#033[34m████▋     #033[0m| 8700/18453 [36:56<39:50,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   8700;#011loss: 0.0000119245;#011Avg. STS: 79.37598;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  47%|#033[34m████▋     #033[0m| 8750/18453 [37:08<39:36,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   8750;#011loss: 0.0000159199;#011Avg. STS: 79.27263;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  48%|#033[34m████▊     #033[0m| 8800/18453 [37:21<39:27,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   8800;#011loss: 0.0000141094;#011Avg. STS: 79.42926;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  48%|#033[34m████▊     #033[0m| 8850/18453 [37:33<39:12,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   8850;#011loss: 0.0000959769;#011Avg. STS: 78.76572;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  48%|#033[34m████▊     #033[0m| 8900/18453 [37:45<38:59,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   8900;#011loss: 0.0000280107;#011Avg. STS: 78.77649;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  49%|#033[34m████▊     #033[0m| 8950/18453 [37:57<38:47,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   8950;#011loss: 0.0000181586;#011Avg. STS: 78.91453;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  49%|#033[34m████▉     #033[0m| 9000/18453 [38:10<38:36,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   9000;#011loss: 0.0000163202;#011Avg. STS: 78.52984;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  49%|#033[34m████▉     #033[0m| 9050/18453 [38:22<38:30,  4.07it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   9050;#011loss: 0.0000126491;#011Avg. STS: 79.07220;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  49%|#033[34m████▉     #033[0m| 9100/18453 [38:34<38:16,  4.07it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   9100;#011loss: 0.0000145581;#011Avg. STS: 79.08765;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  50%|#033[34m████▉     #033[0m| 9150/18453 [38:47<38:01,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   9150;#011loss: 0.0000180669;#011Avg. STS: 79.20818;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  50%|#033[34m████▉     #033[0m| 9200/18453 [38:59<37:48,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   9200;#011loss: 0.0000117141;#011Avg. STS: 79.19793;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  50%|#033[34m█████     #033[0m| 9250/18453 [39:11<37:34,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   9250;#011loss: 0.0000120139;#011Avg. STS: 79.14719;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  50%|#033[34m█████     #033[0m| 9300/18453 [39:23<37:22,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   9300;#011loss: 0.0000124871;#011Avg. STS: 79.16298;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  51%|#033[34m█████     #033[0m| 9350/18453 [39:36<37:09,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   9350;#011loss: 0.0000125131;#011Avg. STS: 79.18449;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  51%|#033[34m█████     #033[0m| 9400/18453 [39:48<36:54,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   9400;#011loss: 0.0000120605;#011Avg. STS: 79.12723;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  51%|#033[34m█████     #033[0m| 9450/18453 [40:00<36:43,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   9450;#011loss: 0.0000160968;#011Avg. STS: 79.47958;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  51%|#033[34m█████▏    #033[0m| 9500/18453 [40:12<36:32,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   9500;#011loss: 0.0000151617;#011Avg. STS: 79.27931;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  52%|#033[34m█████▏    #033[0m| 9550/18453 [40:24<36:20,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   9550;#011loss: 0.0000158155;#011Avg. STS: 79.13898;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  52%|#033[34m█████▏    #033[0m| 9600/18453 [40:37<36:08,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   9600;#011loss: 0.0000198329;#011Avg. STS: 79.17172;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  52%|#033[34m█████▏    #033[0m| 9650/18453 [40:49<35:56,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   9650;#011loss: 0.0000189797;#011Avg. STS: 79.48523;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  53%|#033[34m█████▎    #033[0m| 9700/18453 [41:01<35:43,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   9700;#011loss: 0.0000167710;#011Avg. STS: 79.37202;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  53%|#033[34m█████▎    #033[0m| 9750/18453 [41:13<35:30,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   9750;#011loss: 0.0000140720;#011Avg. STS: 79.38069;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  53%|#033[34m█████▎    #033[0m| 9800/18453 [41:26<35:16,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   9800;#011loss: 0.0000189239;#011Avg. STS: 79.34105;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  53%|#033[34m█████▎    #033[0m| 9850/18453 [41:38<35:03,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   9850;#011loss: 0.0000192748;#011Avg. STS: 79.34697;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  54%|#033[34m█████▎    #033[0m| 9900/18453 [41:50<34:52,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   9900;#011loss: 0.0000163109;#011Avg. STS: 79.33178;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  54%|#033[34m█████▍    #033[0m| 9950/18453 [42:02<34:41,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:   9950;#011loss: 0.0000979219;#011Avg. STS: 78.95274;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  54%|#033[34m█████▍    #033[0m| 10000/18453 [42:15<34:27,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  10000;#011loss: 0.0000164935;#011Avg. STS: 78.90539;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  54%|#033[34m█████▍    #033[0m| 10050/18453 [42:27<34:14,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  10050;#011loss: 0.0000174918;#011Avg. STS: 78.91850;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  55%|#033[34m█████▍    #033[0m| 10100/18453 [42:39<34:01,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  10100;#011loss: 0.0000368414;#011Avg. STS: 78.88830;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  55%|#033[34m█████▌    #033[0m| 10150/18453 [42:51<33:48,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  10150;#011loss: 0.0000175793;#011Avg. STS: 78.77414;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  55%|#033[34m█████▌    #033[0m| 10200/18453 [43:03<33:37,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  10200;#011loss: 0.0000173856;#011Avg. STS: 78.63418;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  56%|#033[34m█████▌    #033[0m| 10250/18453 [43:16<33:25,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  10250;#011loss: 0.0000160092;#011Avg. STS: 78.95071;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  56%|#033[34m█████▌    #033[0m| 10300/18453 [43:28<33:12,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  10300;#011loss: 0.0000283004;#011Avg. STS: 78.82043;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  56%|#033[34m█████▌    #033[0m| 10350/18453 [43:40<33:06,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  10350;#011loss: 0.0000178551;#011Avg. STS: 78.85520;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  56%|#033[34m█████▋    #033[0m| 10400/18453 [43:52<32:53,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  10400;#011loss: 0.0000116842;#011Avg. STS: 78.90111;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  57%|#033[34m█████▋    #033[0m| 10450/18453 [44:05<32:40,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  10450;#011loss: 0.0000152865;#011Avg. STS: 78.88874;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  57%|#033[34m█████▋    #033[0m| 10500/18453 [44:17<32:26,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  10500;#011loss: 0.0000101029;#011Avg. STS: 79.00427;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  57%|#033[34m█████▋    #033[0m| 10550/18453 [44:29<32:11,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  10550;#011loss: 0.0000131929;#011Avg. STS: 78.96304;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  57%|#033[34m█████▋    #033[0m| 10600/18453 [44:41<31:57,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  10600;#011loss: 0.0000140796;#011Avg. STS: 78.75512;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  58%|#033[34m█████▊    #033[0m| 10650/18453 [44:53<31:43,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  10650;#011loss: 0.0000106263;#011Avg. STS: 78.85054;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  58%|#033[34m█████▊    #033[0m| 10700/18453 [45:06<31:31,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  10700;#011loss: 0.0000108796;#011Avg. STS: 78.84799;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  58%|#033[34m█████▊    #033[0m| 10750/18453 [45:18<31:19,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  10750;#011loss: 0.0000132618;#011Avg. STS: 78.84421;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  59%|#033[34m█████▊    #033[0m| 10800/18453 [45:30<31:07,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  10800;#011loss: 0.0000194412;#011Avg. STS: 78.86225;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  59%|#033[34m█████▉    #033[0m| 10850/18453 [45:42<30:54,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  10850;#011loss: 0.0000139361;#011Avg. STS: 78.80617;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  59%|#033[34m█████▉    #033[0m| 10900/18453 [45:54<30:40,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  10900;#011loss: 0.0000122952;#011Avg. STS: 78.72111;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  59%|#033[34m█████▉    #033[0m| 10950/18453 [46:07<30:29,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  10950;#011loss: 0.0000110435;#011Avg. STS: 78.75723;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  60%|#033[34m█████▉    #033[0m| 11000/18453 [46:19<30:18,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  11000;#011loss: 0.0000125913;#011Avg. STS: 78.70987;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  60%|#033[34m█████▉    #033[0m| 11050/18453 [46:31<30:07,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  11050;#011loss: 0.0000456611;#011Avg. STS: 78.85906;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  60%|#033[34m██████    #033[0m| 11100/18453 [46:43<29:56,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  11100;#011loss: 0.0000136977;#011Avg. STS: 79.46688;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  60%|#033[34m██████    #033[0m| 11150/18453 [46:55<29:44,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  11150;#011loss: 0.0000463737;#011Avg. STS: 79.13547;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  61%|#033[34m██████    #033[0m| 11200/18453 [47:08<29:32,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  11200;#011loss: 0.0000165754;#011Avg. STS: 79.15420;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  61%|#033[34m██████    #033[0m| 11250/18453 [47:20<29:19,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  11250;#011loss: 0.0000168790;#011Avg. STS: 79.13762;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  61%|#033[34m██████    #033[0m| 11300/18453 [47:32<29:08,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  11300;#011loss: 0.0000234522;#011Avg. STS: 79.36004;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  62%|#033[34m██████▏   #033[0m| 11350/18453 [47:44<28:54,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  11350;#011loss: 0.0000163351;#011Avg. STS: 79.45797;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  62%|#033[34m██████▏   #033[0m| 11400/18453 [47:57<28:40,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  11400;#011loss: 0.0000113453;#011Avg. STS: 79.38241;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  62%|#033[34m██████▏   #033[0m| 11450/18453 [48:09<28:28,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  11450;#011loss: 0.0000149866;#011Avg. STS: 79.43566;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  62%|#033[34m██████▏   #033[0m| 11500/18453 [48:21<28:16,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  11500;#011loss: 0.0000127460;#011Avg. STS: 79.49997;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  63%|#033[34m██████▎   #033[0m| 11550/18453 [48:33<28:04,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  11550;#011loss: 0.0000195928;#011Avg. STS: 79.18289;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  63%|#033[34m██████▎   #033[0m| 11600/18453 [48:45<27:51,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  11600;#011loss: 0.0000141131;#011Avg. STS: 79.12718;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  63%|#033[34m██████▎   #033[0m| 11650/18453 [48:58<27:39,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  11650;#011loss: 0.0000580761;#011Avg. STS: 78.57831;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  63%|#033[34m██████▎   #033[0m| 11700/18453 [49:10<27:26,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  11700;#011loss: 0.0000150072;#011Avg. STS: 77.61191;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  64%|#033[34m██████▎   #033[0m| 11750/18453 [49:22<27:14,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  11750;#011loss: 0.0000163258;#011Avg. STS: 77.65793;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  64%|#033[34m██████▍   #033[0m| 11800/18453 [49:34<27:04,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  11800;#011loss: 0.0000644173;#011Avg. STS: 77.76413;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  64%|#033[34m██████▍   #033[0m| 11850/18453 [49:46<26:54,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  11850;#011loss: 0.0001107055;#011Avg. STS: 76.57765;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  64%|#033[34m██████▍   #033[0m| 11900/18453 [49:59<26:39,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  11900;#011loss: 0.0000175439;#011Avg. STS: 77.16476;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  65%|#033[34m██████▍   #033[0m| 11950/18453 [50:11<26:24,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  11950;#011loss: 0.0000232286;#011Avg. STS: 77.35800;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  65%|#033[34m██████▌   #033[0m| 12000/18453 [50:23<26:11,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  12000;#011loss: 0.0000202819;#011Avg. STS: 77.89826;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  65%|#033[34m██████▌   #033[0m| 12050/18453 [50:35<26:00,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  12050;#011loss: 0.0000183934;#011Avg. STS: 78.10364;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  66%|#033[34m██████▌   #033[0m| 12100/18453 [50:47<25:46,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  12100;#011loss: 0.0000197802;#011Avg. STS: 78.11971;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  66%|#033[34m██████▌   #033[0m| 12150/18453 [50:59<25:33,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  12150;#011loss: 0.0000217843;#011Avg. STS: 78.50215;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  66%|#033[34m██████▌   #033[0m| 12200/18453 [51:11<25:20,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  12200;#011loss: 0.0000151300;#011Avg. STS: 78.46020;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  66%|#033[34m██████▋   #033[0m| 12250/18453 [51:24<25:07,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  12250;#011loss: 0.0000156739;#011Avg. STS: 78.70220;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  67%|#033[34m██████▋   #033[0m| 12300/18453 [51:36<24:55,  4.12it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  12300;#011loss: 0.0000161675;#011Avg. STS: 78.73470;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  67%|#033[34m██████▋   #033[0m| 12350/18453 [51:48<24:43,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  12350;#011loss: 0.0000189147;#011Avg. STS: 78.91808;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  67%|#033[34m██████▋   #033[0m| 12400/18453 [52:00<24:31,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  12400;#011loss: 0.0000155060;#011Avg. STS: 78.93181;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  67%|#033[34m██████▋   #033[0m| 12450/18453 [52:12<24:22,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  12450;#011loss: 0.0000140870;#011Avg. STS: 78.87011;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  68%|#033[34m██████▊   #033[0m| 12500/18453 [52:24<24:08,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  12500;#011loss: 0.0000091772;#011Avg. STS: 78.83598;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  68%|#033[34m██████▊   #033[0m| 12550/18453 [52:37<23:55,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  12550;#011loss: 0.0000141093;#011Avg. STS: 78.87812;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  68%|#033[34m██████▊   #033[0m| 12600/18453 [52:49<23:43,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  12600;#011loss: 0.0000214238;#011Avg. STS: 79.09667;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  69%|#033[34m██████▊   #033[0m| 12650/18453 [53:01<23:32,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  12650;#011loss: 0.0000157801;#011Avg. STS: 79.12043;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  69%|#033[34m██████▉   #033[0m| 12700/18453 [53:13<23:21,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  12700;#011loss: 0.0000126119;#011Avg. STS: 79.09668;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  69%|#033[34m██████▉   #033[0m| 12750/18453 [53:25<23:11,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  12750;#011loss: 0.0000139920;#011Avg. STS: 79.10186;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  69%|#033[34m██████▉   #033[0m| 12800/18453 [53:38<22:59,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  12800;#011loss: 0.0000138393;#011Avg. STS: 79.16662;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  70%|#033[34m██████▉   #033[0m| 12850/18453 [53:50<22:47,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  12850;#011loss: 0.0000138914;#011Avg. STS: 79.24393;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  70%|#033[34m██████▉   #033[0m| 12900/18453 [54:02<22:35,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  12900;#011loss: 0.0000161321;#011Avg. STS: 79.23762;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  70%|#033[34m███████   #033[0m| 12950/18453 [54:14<22:23,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  12950;#011loss: 0.0000150183;#011Avg. STS: 79.23486;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  70%|#033[34m███████   #033[0m| 13000/18453 [54:27<22:14,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  13000;#011loss: 0.0000130272;#011Avg. STS: 79.27295;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  71%|#033[34m███████   #033[0m| 13050/18453 [54:39<22:01,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  13050;#011loss: 0.0000451318;#011Avg. STS: 77.79527;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  71%|#033[34m███████   #033[0m| 13100/18453 [54:51<21:49,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  13100;#011loss: 0.0000301238;#011Avg. STS: 78.41794;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  71%|#033[34m███████▏  #033[0m| 13150/18453 [55:03<21:36,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  13150;#011loss: 0.0000123436;#011Avg. STS: 78.57822;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  72%|#033[34m███████▏  #033[0m| 13200/18453 [55:15<21:22,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  13200;#011loss: 0.0000267972;#011Avg. STS: 78.31875;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  72%|#033[34m███████▏  #033[0m| 13250/18453 [55:28<21:09,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  13250;#011loss: 0.0000179463;#011Avg. STS: 78.44887;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  72%|#033[34m███████▏  #033[0m| 13300/18453 [55:40<20:56,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  13300;#011loss: 0.0000172998;#011Avg. STS: 78.53308;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  72%|#033[34m███████▏  #033[0m| 13350/18453 [55:52<20:43,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  13350;#011loss: 0.0000277971;#011Avg. STS: 78.64494;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  73%|#033[34m███████▎  #033[0m| 13400/18453 [56:04<20:30,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  13400;#011loss: 0.0000210287;#011Avg. STS: 78.88007;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  73%|#033[34m███████▎  #033[0m| 13450/18453 [56:16<20:17,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  13450;#011loss: 0.0000205033;#011Avg. STS: 78.95977;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  73%|#033[34m███████▎  #033[0m| 13500/18453 [56:28<20:05,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  13500;#011loss: 0.0000109746;#011Avg. STS: 78.98855;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  73%|#033[34m███████▎  #033[0m| 13550/18453 [56:41<19:52,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  13550;#011loss: 0.0000128503;#011Avg. STS: 78.93246;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  74%|#033[34m███████▎  #033[0m| 13600/18453 [56:53<19:41,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  13600;#011loss: 0.0000195740;#011Avg. STS: 78.93925;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  74%|#033[34m███████▍  #033[0m| 13650/18453 [57:05<19:28,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  13650;#011loss: 0.0000128447;#011Avg. STS: 78.95339;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  74%|#033[34m███████▍  #033[0m| 13700/18453 [57:17<19:16,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  13700;#011loss: 0.0000135897;#011Avg. STS: 78.95548;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  75%|#033[34m███████▍  #033[0m| 13750/18453 [57:29<19:04,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  13750;#011loss: 0.0000126826;#011Avg. STS: 78.95945;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  75%|#033[34m███████▍  #033[0m| 13800/18453 [57:41<18:53,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  13800;#011loss: 0.0000115837;#011Avg. STS: 78.97575;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  75%|#033[34m███████▌  #033[0m| 13850/18453 [57:54<18:41,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  13850;#011loss: 0.0000136977;#011Avg. STS: 79.01098;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  75%|#033[34m███████▌  #033[0m| 13900/18453 [58:06<18:28,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  13900;#011loss: 0.0000133364;#011Avg. STS: 79.06567;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  76%|#033[34m███████▌  #033[0m| 13950/18453 [58:18<18:18,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  13950;#011loss: 0.0000118202;#011Avg. STS: 79.02811;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  76%|#033[34m███████▌  #033[0m| 14000/18453 [58:30<18:06,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  14000;#011loss: 0.0000110491;#011Avg. STS: 79.05719;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  76%|#033[34m███████▌  #033[0m| 14050/18453 [58:42<17:54,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  14050;#011loss: 0.0000242585;#011Avg. STS: 79.06496;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  76%|#033[34m███████▋  #033[0m| 14100/18453 [58:55<17:42,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  14100;#011loss: 0.0000122896;#011Avg. STS: 79.14778;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  77%|#033[34m███████▋  #033[0m| 14150/18453 [59:07<17:30,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  14150;#011loss: 0.0000159683;#011Avg. STS: 79.12258;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  77%|#033[34m███████▋  #033[0m| 14200/18453 [59:19<17:18,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  14200;#011loss: 0.0000145954;#011Avg. STS: 79.16777;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  77%|#033[34m███████▋  #033[0m| 14250/18453 [59:31<17:07,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  14250;#011loss: 0.0000231985;#011Avg. STS: 78.55782;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  77%|#033[34m███████▋  #033[0m| 14300/18453 [59:44<16:54,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  14300;#011loss: 0.0000131110;#011Avg. STS: 78.62763;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  78%|#033[34m███████▊  #033[0m| 14350/18453 [59:56<16:41,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  14350;#011loss: 0.0000138933;#011Avg. STS: 78.68008;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  78%|#033[34m███████▊  #033[0m| 14400/18453 [1:00:08<16:29,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  14400;#011loss: 0.0000213601;#011Avg. STS: 78.72211;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  78%|#033[34m███████▊  #033[0m| 14450/18453 [1:00:20<16:20,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  14450;#011loss: 0.0000125522;#011Avg. STS: 78.75246;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  79%|#033[34m███████▊  #033[0m| 14500/18453 [1:00:32<16:07,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  14500;#011loss: 0.0000140311;#011Avg. STS: 78.94080;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  79%|#033[34m███████▉  #033[0m| 14550/18453 [1:00:45<15:55,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  14550;#011loss: 0.0000219415;#011Avg. STS: 78.88879;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  79%|#033[34m███████▉  #033[0m| 14600/18453 [1:00:57<15:42,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  14600;#011loss: 0.0000115818;#011Avg. STS: 79.06555;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  79%|#033[34m███████▉  #033[0m| 14650/18453 [1:01:09<15:30,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  14650;#011loss: 0.0000124479;#011Avg. STS: 79.10521;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  80%|#033[34m███████▉  #033[0m| 14700/18453 [1:01:21<15:17,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  14700;#011loss: 0.0000167673;#011Avg. STS: 79.19365;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  80%|#033[34m███████▉  #033[0m| 14750/18453 [1:01:34<15:08,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  14750;#011loss: 0.0000200138;#011Avg. STS: 79.36567;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  80%|#033[34m████████  #033[0m| 14800/18453 [1:01:46<14:55,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  14800;#011loss: 0.0000114589;#011Avg. STS: 79.18823;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  80%|#033[34m████████  #033[0m| 14850/18453 [1:01:58<14:42,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  14850;#011loss: 0.0000139342;#011Avg. STS: 79.23878;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  81%|#033[34m████████  #033[0m| 14900/18453 [1:02:11<14:31,  4.07it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  14900;#011loss: 0.0000144203;#011Avg. STS: 79.26019;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  81%|#033[34m████████  #033[0m| 14950/18453 [1:02:23<14:18,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  14950;#011loss: 0.0000172516;#011Avg. STS: 78.65050;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  81%|#033[34m████████▏ #033[0m| 15000/18453 [1:02:35<14:05,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  15000;#011loss: 0.0000138560;#011Avg. STS: 78.82654;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  82%|#033[34m████████▏ #033[0m| 15050/18453 [1:02:47<13:53,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  15050;#011loss: 0.0000192685;#011Avg. STS: 78.85674;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  82%|#033[34m████████▏ #033[0m| 15100/18453 [1:02:59<13:40,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  15100;#011loss: 0.0000178046;#011Avg. STS: 78.92373;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  82%|#033[34m████████▏ #033[0m| 15150/18453 [1:03:12<13:26,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  15150;#011loss: 0.0000121704;#011Avg. STS: 78.96131;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  82%|#033[34m████████▏ #033[0m| 15200/18453 [1:03:24<13:14,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  15200;#011loss: 0.0000115762;#011Avg. STS: 78.90989;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  83%|#033[34m████████▎ #033[0m| 15250/18453 [1:03:36<13:02,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  15250;#011loss: 0.0000121033;#011Avg. STS: 78.90476;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  83%|#033[34m████████▎ #033[0m| 15300/18453 [1:03:48<12:50,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  15300;#011loss: 0.0000130457;#011Avg. STS: 78.90261;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  83%|#033[34m████████▎ #033[0m| 15350/18453 [1:04:01<12:38,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  15350;#011loss: 0.0000102202;#011Avg. STS: 78.91798;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  83%|#033[34m████████▎ #033[0m| 15400/18453 [1:04:13<12:25,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  15400;#011loss: 0.0000169443;#011Avg. STS: 79.00145;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  84%|#033[34m████████▎ #033[0m| 15450/18453 [1:04:25<12:12,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  15450;#011loss: 0.0000127087;#011Avg. STS: 78.97123;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  84%|#033[34m████████▍ #033[0m| 15500/18453 [1:04:37<11:59,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  15500;#011loss: 0.0000128950;#011Avg. STS: 78.94247;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  84%|#033[34m████████▍ #033[0m| 15550/18453 [1:04:49<11:47,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  15550;#011loss: 0.0000099576;#011Avg. STS: 78.92593;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  85%|#033[34m████████▍ #033[0m| 15600/18453 [1:05:01<11:35,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  15600;#011loss: 0.0000158043;#011Avg. STS: 78.91028;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  85%|#033[34m████████▍ #033[0m| 15650/18453 [1:05:14<11:22,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  15650;#011loss: 0.0000129229;#011Avg. STS: 78.94041;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  85%|#033[34m████████▌ #033[0m| 15700/18453 [1:05:26<11:10,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  15700;#011loss: 0.0000104717;#011Avg. STS: 78.86260;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  85%|#033[34m████████▌ #033[0m| 15750/18453 [1:05:38<10:59,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  15750;#011loss: 0.0000155063;#011Avg. STS: 78.68230;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  86%|#033[34m████████▌ #033[0m| 15800/18453 [1:05:50<10:46,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  15800;#011loss: 0.0000237690;#011Avg. STS: 78.79211;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  86%|#033[34m████████▌ #033[0m| 15850/18453 [1:06:02<10:34,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  15850;#011loss: 0.0000118705;#011Avg. STS: 78.83836;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  86%|#033[34m████████▌ #033[0m| 15900/18453 [1:06:14<10:21,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  15900;#011loss: 0.0000103637;#011Avg. STS: 78.83142;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  86%|#033[34m████████▋ #033[0m| 15950/18453 [1:06:27<10:09,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  15950;#011loss: 0.0000320869;#011Avg. STS: 78.92266;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  87%|#033[34m████████▋ #033[0m| 16000/18453 [1:06:39<09:57,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  16000;#011loss: 0.0000155230;#011Avg. STS: 78.96331;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  87%|#033[34m████████▋ #033[0m| 16050/18453 [1:06:51<09:45,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  16050;#011loss: 0.0000135040;#011Avg. STS: 79.02016;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  87%|#033[34m████████▋ #033[0m| 16100/18453 [1:07:03<09:33,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  16100;#011loss: 0.0000174647;#011Avg. STS: 79.03708;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  88%|#033[34m████████▊ #033[0m| 16150/18453 [1:07:15<09:20,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  16150;#011loss: 0.0000117159;#011Avg. STS: 79.06158;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  88%|#033[34m████████▊ #033[0m| 16200/18453 [1:07:28<09:08,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  16200;#011loss: 0.0000167633;#011Avg. STS: 79.07671;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  88%|#033[34m████████▊ #033[0m| 16250/18453 [1:07:40<08:56,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  16250;#011loss: 0.0000104270;#011Avg. STS: 79.02982;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  88%|#033[34m████████▊ #033[0m| 16300/18453 [1:07:52<08:44,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  16300;#011loss: 0.0000155305;#011Avg. STS: 79.02932;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  89%|#033[34m████████▊ #033[0m| 16350/18453 [1:08:04<08:31,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  16350;#011loss: 0.0000136530;#011Avg. STS: 79.03071;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  89%|#033[34m████████▉ #033[0m| 16400/18453 [1:08:16<08:19,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  16400;#011loss: 0.0000113154;#011Avg. STS: 79.04076;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  89%|#033[34m████████▉ #033[0m| 16450/18453 [1:08:28<08:07,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  16450;#011loss: 0.0000151319;#011Avg. STS: 79.02039;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  89%|#033[34m████████▉ #033[0m| 16500/18453 [1:08:41<07:55,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  16500;#011loss: 0.0000105239;#011Avg. STS: 79.06501;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  90%|#033[34m████████▉ #033[0m| 16550/18453 [1:08:53<07:42,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  16550;#011loss: 0.0000255890;#011Avg. STS: 79.06520;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  90%|#033[34m████████▉ #033[0m| 16600/18453 [1:09:05<07:31,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  16600;#011loss: 0.0000096186;#011Avg. STS: 79.01259;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  90%|#033[34m█████████ #033[0m| 16650/18453 [1:09:17<07:19,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  16650;#011loss: 0.0000113341;#011Avg. STS: 78.98305;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  91%|#033[34m█████████ #033[0m| 16700/18453 [1:09:29<07:07,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  16700;#011loss: 0.0000140237;#011Avg. STS: 78.90708;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  91%|#033[34m█████████ #033[0m| 16750/18453 [1:09:42<06:55,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  16750;#011loss: 0.0000098980;#011Avg. STS: 78.94281;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  91%|#033[34m█████████ #033[0m| 16800/18453 [1:09:54<06:43,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  16800;#011loss: 0.0000117718;#011Avg. STS: 78.96036;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  91%|#033[34m█████████▏#033[0m| 16850/18453 [1:10:06<06:30,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  16850;#011loss: 0.0000118649;#011Avg. STS: 78.96328;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  92%|#033[34m█████████▏#033[0m| 16900/18453 [1:10:18<06:18,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  16900;#011loss: 0.0000121313;#011Avg. STS: 78.97399;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  92%|#033[34m█████████▏#033[0m| 16950/18453 [1:10:30<06:06,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  16950;#011loss: 0.0000132841;#011Avg. STS: 78.97336;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  92%|#033[34m█████████▏#033[0m| 17000/18453 [1:10:42<05:53,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  17000;#011loss: 0.0000086110;#011Avg. STS: 78.95822;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  92%|#033[34m█████████▏#033[0m| 17050/18453 [1:10:55<05:41,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  17050;#011loss: 0.0000114291;#011Avg. STS: 78.92360;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  93%|#033[34m█████████▎#033[0m| 17100/18453 [1:11:07<05:30,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  17100;#011loss: 0.0000120847;#011Avg. STS: 78.97924;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  93%|#033[34m█████████▎#033[0m| 17150/18453 [1:11:19<05:17,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  17150;#011loss: 0.0000186634;#011Avg. STS: 79.10442;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  93%|#033[34m█████████▎#033[0m| 17200/18453 [1:11:31<05:05,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  17200;#011loss: 0.0000105741;#011Avg. STS: 79.11686;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  93%|#033[34m█████████▎#033[0m| 17250/18453 [1:11:43<04:53,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  17250;#011loss: 0.0000112316;#011Avg. STS: 79.11890;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  94%|#033[34m█████████▍#033[0m| 17300/18453 [1:11:56<04:40,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  17300;#011loss: 0.0000107455;#011Avg. STS: 79.11543;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  94%|#033[34m█████████▍#033[0m| 17350/18453 [1:12:08<04:28,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  17350;#011loss: 0.0000109019;#011Avg. STS: 79.11836;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  94%|#033[34m█████████▍#033[0m| 17400/18453 [1:12:20<04:16,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  17400;#011loss: 0.0000100284;#011Avg. STS: 79.10962;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  95%|#033[34m█████████▍#033[0m| 17450/18453 [1:12:32<04:04,  4.11it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  17450;#011loss: 0.0000124069;#011Avg. STS: 79.10193;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  95%|#033[34m█████████▍#033[0m| 17500/18453 [1:12:44<03:52,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  17500;#011loss: 0.0000148246;#011Avg. STS: 79.12090;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  95%|#033[34m█████████▌#033[0m| 17550/18453 [1:12:56<03:40,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  17550;#011loss: 0.0000102221;#011Avg. STS: 79.12127;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  95%|#033[34m█████████▌#033[0m| 17600/18453 [1:13:09<03:28,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  17600;#011loss: 0.0000153124;#011Avg. STS: 79.12542;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  96%|#033[34m█████████▌#033[0m| 17650/18453 [1:13:21<03:15,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  17650;#011loss: 0.0000101234;#011Avg. STS: 79.13126;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  96%|#033[34m█████████▌#033[0m| 17700/18453 [1:13:33<03:03,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  17700;#011loss: 0.0000092927;#011Avg. STS: 79.14049;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  96%|#033[34m█████████▌#033[0m| 17750/18453 [1:13:45<02:51,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  17750;#011loss: 0.0000115688;#011Avg. STS: 79.17735;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  96%|#033[34m█████████▋#033[0m| 17800/18453 [1:13:57<02:39,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  17800;#011loss: 0.0000106896;#011Avg. STS: 79.18010;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  97%|#033[34m█████████▋#033[0m| 17850/18453 [1:14:10<02:27,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  17850;#011loss: 0.0000114104;#011Avg. STS: 79.17623;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  97%|#033[34m█████████▋#033[0m| 17900/18453 [1:14:22<02:14,  4.10it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  17900;#011loss: 0.0000111013;#011Avg. STS: 79.17180;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  97%|#033[34m█████████▋#033[0m| 17950/18453 [1:14:34<02:02,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  17950;#011loss: 0.0000122207;#011Avg. STS: 79.16915;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  98%|#033[34m█████████▊#033[0m| 18000/18453 [1:14:46<01:50,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  18000;#011loss: 0.0000105089;#011Avg. STS: 79.15464;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  98%|#033[34m█████████▊#033[0m| 18050/18453 [1:14:59<01:38,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  18050;#011loss: 0.0000087022;#011Avg. STS: 79.15407;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  98%|#033[34m█████████▊#033[0m| 18100/18453 [1:15:11<01:26,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  18100;#011loss: 0.0000109262;#011Avg. STS: 79.16110;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  98%|#033[34m█████████▊#033[0m| 18150/18453 [1:15:23<01:14,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  18150;#011loss: 0.0000143773;#011Avg. STS: 79.17700;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  99%|#033[34m█████████▊#033[0m| 18200/18453 [1:15:35<01:02,  4.07it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  18200;#011loss: 0.0000105201;#011Avg. STS: 79.15471;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  99%|#033[34m█████████▉#033[0m| 18250/18453 [1:15:48<00:49,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  18250;#011loss: 0.0002262756;#011Avg. STS: 79.16036;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  99%|#033[34m█████████▉#033[0m| 18300/18453 [1:16:00<00:37,  4.08it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  18300;#011loss: 0.0000083539;#011Avg. STS: 79.18028;\u001b[0m\n",
      "\u001b[34mTraining epoch 1:  99%|#033[34m█████████▉#033[0m| 18350/18453 [1:16:12<00:25,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  18350;#011loss: 0.0000140013;#011Avg. STS: 79.18021;\u001b[0m\n",
      "\u001b[34mTraining epoch 1: 100%|#033[34m█████████▉#033[0m| 18400/18453 [1:16:24<00:12,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  18400;#011loss: 0.0000112391;#011Avg. STS: 79.19598;\u001b[0m\n",
      "\u001b[34mTraining epoch 1: 100%|#033[34m█████████▉#033[0m| 18450/18453 [1:16:37<00:00,  4.09it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  18450;#011loss: 0.0000116284;#011Avg. STS: 79.19541;\u001b[0m\n",
      "\u001b[34mTraining epoch 1: 18500it [1:16:38,  5.55it/s]\u001b[0m\n",
      "\u001b[34mepoch:   1;#011step:  18453;#011loss: 0.0000131184;#011Avg. STS: 79.19544;\u001b[0m\n",
      "\u001b[34mTraining epoch 1: 18500it [1:16:39,  5.55it/s]\u001b[0m\n",
      "\u001b[34m10/05/2023 10:08:57 - INFO - root -   Distributed Training finished successfully!\u001b[0m\n",
      "\u001b[34mTraining epoch 1: 18500it [1:16:39,  4.02it/s]\u001b[0m\n",
      "\u001b[34m10/05/2023 10:08:57 - INFO - root -   Elapsed time: 1:16:54.505734\u001b[0m\n",
      "\u001b[34m2023-10-05 10:09:02,063 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-10-05 10:09:02,063 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-10-05 10:09:02,063 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 5010\n",
      "Billable seconds: 5010\n"
     ]
    }
   ],
   "source": [
    "sess.logs_for_job(job_name=train_job_name, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ede3eb-dcf3-4ba0-9845-fcba5892cc4b",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 3. Inference\n",
    "---\n",
    "#### Copy S3 model artifact to local directory\n",
    "S3에 저장된 모델 아티팩트를 로컬 경로로 복사하여 압축을 해제합니다. 필요 시 로컬 환경에서 모델을 로드하여 추론을 수행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72a9c8b5-f602-4ebc-85cc-54dbe7a5d8eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "download: s3://sagemaker-us-east-1-143656149352/kosimcse-roberta-base-unsupervised-2023-2023-10-05-08-45-35-241/output/model.tar.gz to model_from_sagemaker/model.tar.gz\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import json, os\n",
    "\n",
    "local_model_dir = 'model_from_sagemaker'\n",
    "\n",
    "if not os.path.exists(local_model_dir):\n",
    "    os.makedirs(local_model_dir)\n",
    "\n",
    "!aws s3 cp {estimator.model_data} {local_model_dir}/model.tar.gz\n",
    "!tar -xzf {local_model_dir}/model.tar.gz -C {local_model_dir}\n",
    "!rm -rf {local_model_dir}/model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a8facd-c0a4-4c63-b6f1-e3247a9e4367",
   "metadata": {},
   "source": [
    "### Load model artifact "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ec49ed92-7148-49d6-817b-55eae9684a89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import torch\n",
    "import transformers\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from transformers import BertForSequenceClassification, AutoTokenizer\n",
    "from src.simcse import SimCSEModel\n",
    "from src.infer import show_embedding_score\n",
    "\n",
    "with open(f'{local_model_dir}/config.json') as f:\n",
    "    json_object = json.load(f)\n",
    "    \n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')        \n",
    "base_model = json_object[\"base_model\"]\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "model = SimCSEModel(base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3b642393-f462-4ca2-864a-11fc7cb65666",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_filename = glob.glob(f'{local_model_dir}/*.pt')[0]\n",
    "state_dict = torch.load(model_filename)['model']\n",
    "\n",
    "new_state_dict = {}\n",
    "for key in state_dict:\n",
    "    new_key = key.replace('module.','')\n",
    "    new_state_dict[new_key] = state_dict[key]\n",
    "\n",
    "model.load_state_dict(new_state_dict)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2999b1-ada3-4e48-a4f2-96390cf7d590",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "09a924a9-a742-4c4e-a681-62253aca74ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[95.7783]], grad_fn=<MulBackward0>) tensor([[83.8387]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sentences = ['이번 주 일요일에 분당 이마트 점은 문을 여나요?',\n",
    "             '일요일에 분당 이마트는 문 열어요?',\n",
    "             '분당 이마트 점은 토요일에 몇 시까지 하나요']\n",
    "show_embedding_score(tokenizer, model.cpu(), sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9713af4f-a8e5-4a2c-a0a2-cb0d2ded331c",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e586dbf1-a9ca-4983-8eee-f9c4fc80229b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                             \r"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from src.sts import STSEvaluation\n",
    "from more_itertools import chunked\n",
    "batch_size = 128\n",
    "model = model.to(device)\n",
    "\n",
    "@torch.inference_mode()\n",
    "def encode(texts: List[str]) -> torch.Tensor:\n",
    "    embs = []\n",
    "    for text in chunked(texts, batch_size):\n",
    "        batch: BatchEncoding = tokenizer(\n",
    "            text,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        emb = model(**batch.to(device))#, use_mlp=False)\n",
    "        embs.append(emb.cpu())\n",
    "    return torch.cat(embs, dim=0)\n",
    "\n",
    "evaluation = STSEvaluation()\n",
    "sts_metrics = evaluation(encode=encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d29e7a52-01ec-4682-9f7a-c5e6e7db4241",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kluests': {'avg': 81.17424205664676,\n",
       "  'cosine_pearson': 81.27064484084268,\n",
       "  'cosine_spearman': 80.96402147905421,\n",
       "  'euclidean_pearson': 81.70928422021233,\n",
       "  'euclidean_spearman': 80.97595966498845,\n",
       "  'manhattan_pearson': 81.63813042962009,\n",
       "  'manhattan_spearman': 80.89145224740425,\n",
       "  'dot_pearson': 81.12960434211915,\n",
       "  'dot_spearman': 80.81483922893297},\n",
       " 'korsts': {'avg': 81.20202984625175,\n",
       "  'cosine_pearson': 81.53989801463291,\n",
       "  'cosine_spearman': 81.17979077140225,\n",
       "  'euclidean_pearson': 80.89228178455778,\n",
       "  'euclidean_spearman': 81.20759534407303,\n",
       "  'manhattan_pearson': 80.93781263668384,\n",
       "  'manhattan_spearman': 81.22318198360125,\n",
       "  'dot_pearson': 81.48884158006712,\n",
       "  'dot_spearman': 81.14683665499572}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sts_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
